# Feature engineering 
Feature engineering is a course offered on codecademy. This repository is a collection of exercises I completed for the course.

## Course projects
### Transforming data into features
Techniques for transforming categorical data, scaling data, and working with date-time features are applied to a clothing company dataset from [Kaggle](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews). 

### Wrapper methods
Survey data from a survey conducted by Fabio Mendoza Palechor and Alexis de la Hoz Manotas (sourced from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition+)) are analysed using a regresssion model, with the purpose of predicting whether survey respondents are obese. A number of wrapper methods are testest and compared, including:
- sequential forward selection
- sequential backward floating selection
- recursive feature elimination

### Logistic regression with regularisation
A set of logistic regression models were trained on a [dataset](https://archive.ics.uci.edu/ml/datasets/wine+quality) from the UCI Machine Learning Repository on wine quality using sci-kit learn. The goal of the project was to:
1. implement different logistici classifiers
2. find the best ridge-regularized classifier using hyperparameter tuning
3. implement a tuned lasso-regularised feature selection method

### PCA
>In this project, you will classify particles into gamma(signal) or hadrons(background). Given that the features are correlated, you will perform PCA to get a new set of features, and select the features that contain the most information. The data set was generated by a Monte Carlo program, Corsika, described in D. Heck et al., CORSIKA, A Monte Carlo code to simulate extensive air showers, Forschungszentrum Karlsruhe FZKA 6019 (1998).
